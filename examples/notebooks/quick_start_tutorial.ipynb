{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EquiML Quick Start Tutorial\n",
    "\n",
    "**Welcome to EquiML!** This notebook will guide you through building your first fair AI model.\n",
    "\n",
    "## What you'll learn:\n",
    "- Load and analyze data for bias\n",
    "- Train a fair machine learning model\n",
    "- Evaluate fairness and performance\n",
    "- Generate comprehensive reports\n",
    "\n",
    "## Prerequisites:\n",
    "- Basic Python knowledge\n",
    "- Understanding of machine learning concepts (helpful but not required)\n",
    "\n",
    "Let's build fair AI together! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import EquiML and Load Data\n",
    "\n",
    "First, let's import the EquiML components and load a sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import EquiML components\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from src.data import Data\n",
    "from src.model import Model\n",
    "from src.evaluation import EquiMLEvaluation\n",
    "from src.monitoring import BiasMonitor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"âœ… EquiML imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Adult Income dataset\n",
    "data = Data(\n",
    "    dataset_path='../../tests/data/adult.csv',\n",
    "    sensitive_features=['sex']  # We want to ensure fairness by gender\n",
    ")\n",
    "\n",
    "data.load_data()\n",
    "\n",
    "print(f\"ğŸ“Š Dataset loaded: {len(data.df)} rows, {len(data.df.columns)} columns\")\n",
    "print(f\"ğŸ·ï¸  Columns: {list(data.df.columns)}\")\n",
    "\n",
    "# Preview the data\n",
    "data.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Analyze Data for Potential Bias\n",
    "\n",
    "Before building our model, let's examine the data for potential bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze target variable distribution by gender\n",
    "print(\"ğŸ“ˆ Target variable distribution by gender:\")\n",
    "gender_income = pd.crosstab(data.df['sex'], data.df['income'])\n",
    "print(gender_income)\n",
    "\n",
    "# Calculate outcome rates by gender\n",
    "outcome_rates = gender_income.div(gender_income.sum(axis=1), axis=0)\n",
    "print(\"\\nğŸ“Š Outcome rates by gender:\")\n",
    "print(outcome_rates)\n",
    "\n",
    "# Visualize the bias\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Raw counts\n",
    "gender_income.plot(kind='bar', ax=ax1, title='Income Distribution by Gender (Counts)')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Outcome rates\n",
    "outcome_rates.plot(kind='bar', ax=ax2, title='Income Distribution by Gender (Rates)')\n",
    "ax2.set_ylabel('Rate')\n",
    "ax2.tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate bias score\n",
    "high_income_rates = outcome_rates['>50K']\n",
    "bias_score = abs(high_income_rates['Male'] - high_income_rates['Female'])\n",
    "print(f\"\\nâš–ï¸  Raw bias score: {bias_score:.1%}\")\n",
    "\n",
    "if bias_score > 0.2:\n",
    "    print(\"ğŸ”´ HIGH BIAS detected - immediate action needed!\")\n",
    "elif bias_score > 0.1:\n",
    "    print(\"ğŸŸ¡ MODERATE BIAS detected - improvement recommended\")\n",
    "else:\n",
    "    print(\"ğŸŸ¢ LOW BIAS detected - good fairness baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Preprocess Data with Bias Mitigation\n",
    "\n",
    "Now let's preprocess the data and apply bias mitigation techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "print(\"ğŸ”§ Preprocessing data...\")\n",
    "\n",
    "data.preprocess(\n",
    "    target_column='income',\n",
    "    numerical_features=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'],\n",
    "    categorical_features=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    ")\n",
    "\n",
    "print(f\"âœ… Preprocessing complete: {data.X.shape[1]} features created\")\n",
    "\n",
    "# Apply bias mitigation\n",
    "print(\"\\nâš–ï¸  Applying bias mitigation...\")\n",
    "data.apply_bias_mitigation(method='reweighing')\n",
    "print(\"âœ… Bias mitigation applied\")\n",
    "\n",
    "# Handle class imbalance\n",
    "print(\"\\nğŸ“Š Handling class imbalance...\")\n",
    "data.handle_class_imbalance(method='class_weights')\n",
    "print(\"âœ… Class imbalance handled\")\n",
    "\n",
    "# Split data\n",
    "data.split_data(test_size=0.2, random_state=42)\n",
    "print(f\"\\nğŸ”€ Data split: {len(data.X_train)} training, {len(data.X_test)} testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train Fair AI Model\n",
    "\n",
    "Now let's train a model with fairness constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for training\n",
    "print(\"ğŸ¯ Preparing features for training...\")\n",
    "\n",
    "# Find sensitive feature columns (they get renamed during preprocessing)\n",
    "sensitive_feature_column = [col for col in data.X_train.columns if col.startswith('sex_')][0]\n",
    "print(f\"ğŸ“‹ Sensitive feature column: {sensitive_feature_column}\")\n",
    "\n",
    "# Separate sensitive features from training features\n",
    "sensitive_features_train = data.X_train[sensitive_feature_column]\n",
    "X_train = data.X_train.drop(columns=[sensitive_feature_column])\n",
    "sensitive_features_test = data.X_test[sensitive_feature_column]\n",
    "X_test = data.X_test.drop(columns=[sensitive_feature_column])\n",
    "\n",
    "print(f\"âœ… Features prepared: {X_train.shape[1]} features for training\")\n",
    "\n",
    "# Create and train fair model\n",
    "print(\"\\nğŸ¤– Training fair AI model...\")\n",
    "\n",
    "model = Model(\n",
    "    algorithm='robust_random_forest',           # Use robust algorithm\n",
    "    fairness_constraint='demographic_parity'   # Ensure fair treatment\n",
    ")\n",
    "\n",
    "# Apply stability improvements\n",
    "model.apply_stability_improvements(\n",
    "    X_train, data.y_train,\n",
    "    sensitive_features_train,\n",
    "    stability_method='comprehensive'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    X_train, data.y_train,\n",
    "    sensitive_features=sensitive_features_train\n",
    ")\n",
    "\n",
    "print(\"âœ… Fair AI model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Comprehensive Evaluation\n",
    "\n",
    "Let's evaluate our model for both performance and fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "print(\"ğŸ”® Making predictions...\")\n",
    "predictions = model.predict(X_test)\n",
    "print(f\"âœ… Predictions made for {len(predictions)} test samples\")\n",
    "\n",
    "# Comprehensive evaluation\n",
    "print(\"\\nğŸ“Š Running comprehensive evaluation...\")\n",
    "evaluation = EquiMLEvaluation()\n",
    "metrics = evaluation.evaluate(\n",
    "    model, X_test, data.y_test,\n",
    "    y_pred=predictions,\n",
    "    sensitive_features=sensitive_features_test\n",
    ")\n",
    "\n",
    "print(\"âœ… Evaluation completed!\")\n",
    "\n",
    "# Display key results\n",
    "print(\"\\nğŸ¯ KEY RESULTS:\")\n",
    "print(f\"ğŸ“ˆ Accuracy: {metrics['accuracy']:.1%}\")\n",
    "print(f\"ğŸ“ˆ F1-Score: {metrics['f1_score']:.1%}\")\n",
    "\n",
    "if 'demographic_parity_difference' in metrics:\n",
    "    dp_diff = abs(metrics['demographic_parity_difference'])\n",
    "    print(f\"âš–ï¸  Demographic Parity: {dp_diff:.1%}\")\n",
    "    \n",
    "    if dp_diff <= 0.1:\n",
    "        print(\"   ğŸ† EXCELLENT fairness achieved!\")\n",
    "    elif dp_diff <= 0.2:\n",
    "        print(\"   ğŸ¥ˆ GOOD fairness - minor improvements possible\")\n",
    "    else:\n",
    "        print(\"   âš ï¸  BIAS detected - consider additional mitigation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Set Up Bias Monitoring\n",
    "\n",
    "Let's set up real-time bias monitoring for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up bias monitoring\n",
    "print(\"ğŸ›¡ï¸  Setting up bias monitoring...\")\n",
    "\n",
    "monitor = BiasMonitor(sensitive_features=['sex'])\n",
    "\n",
    "# Monitor current predictions\n",
    "monitoring_result = monitor.monitor_predictions(\n",
    "    predictions,\n",
    "    pd.DataFrame({sensitive_feature_column: sensitive_features_test}),\n",
    "    data.y_test.values\n",
    ")\n",
    "\n",
    "violations = len(monitoring_result['violations'])\n",
    "print(f\"ğŸ” Bias violations detected: {violations}\")\n",
    "\n",
    "if violations == 0:\n",
    "    print(\"âœ… No bias violations - your AI is working fairly!\")\n",
    "else:\n",
    "    print(\"âš ï¸  Bias issues detected:\")\n",
    "    for violation in monitoring_result['violations']:\n",
    "        print(f\"   - {violation}\")\n",
    "\n",
    "# Get monitoring summary\n",
    "summary = monitor.get_monitoring_summary()\n",
    "print(f\"\\nğŸ“‹ Monitoring Summary:\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Generate Comprehensive Report\n",
    "\n",
    "Finally, let's generate a detailed HTML report with actionable recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive report\n",
    "print(\"ğŸ“ Generating comprehensive report...\")\n",
    "\n",
    "evaluation.generate_report(\n",
    "    metrics,\n",
    "    output_path='quick_start_report.html',\n",
    "    template_path='../../src/report_template.html'\n",
    ")\n",
    "\n",
    "print(\"âœ… Report generated: quick_start_report.html\")\n",
    "print(\"   Open this file in your browser to see detailed results!\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\nğŸ‰ CONGRATULATIONS!\")\n",
    "print(\"You've successfully built your first fair AI model!\")\n",
    "print(\"\\nWhat you accomplished:\")\n",
    "print(\"âœ… Loaded and analyzed data for bias\")\n",
    "print(\"âœ… Applied bias mitigation techniques\")\n",
    "print(\"âœ… Trained a stable, robust AI model\")\n",
    "print(\"âœ… Ensured fairness across gender groups\")\n",
    "print(\"âœ… Set up real-time bias monitoring\")\n",
    "print(\"âœ… Generated comprehensive analysis report\")\n",
    "\n",
    "print(\"\\nğŸš€ Next steps:\")\n",
    "print(\"1. Try different algorithms (robust_xgboost, robust_ensemble)\")\n",
    "print(\"2. Experiment with different fairness constraints\")\n",
    "print(\"3. Test with your own datasets\")\n",
    "print(\"4. Explore advanced features in our comprehensive guides\")\n",
    "print(\"\\nğŸŒŸ Join the fair AI movement: https://github.com/mkupermann/EquiML\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}